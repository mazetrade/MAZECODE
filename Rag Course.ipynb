{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers PDF trouv√©s : 13\n",
      "- BASF_sustainability_report_2024.pdf\n",
      "- Bayer_sustainability_report_2024.pdf\n",
      "- Cargill_sustainability_report_2024.pdf\n",
      "- CK_Hutchinson _sustainability_report_2024.pdf\n",
      "- Honeywell_sustainability_report_2024.pdf\n",
      "- Merck_sustainability_report_2024.pdf\n",
      "- Microsoft_sustainability_report_2024.pdf\n",
      "- Qualcomm_sustainability_report_2023.pdf\n",
      "- Shell_sustainability_report_2023.pdf\n",
      "- Thai_Oil_sustainability_report_2023.pdf\n",
      "- Veolia_sustainability_report_2024.pdf\n",
      "- Verizon_sustainability_report_2023.pdf\n",
      "- Walmart_sustainability_report_2023.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Chemin vers votre dossier contenant les PDF\n",
    "pdf_folder = r\"C:\\Users\\Mazen ISMAIL\\Downloads\\Rag project\\Data\"\n",
    "\n",
    "# R√©cup√©rer tous les fichiers PDF dans le dossier\n",
    "pdf_files = glob.glob(os.path.join(pdf_folder, \"*.pdf\"))\n",
    "print(f\"Nombre de fichiers PDF trouv√©s : {len(pdf_files)}\")\n",
    "\n",
    "# Afficher les noms des fichiers trouv√©s\n",
    "for pdf in pdf_files:\n",
    "    print(f\"- {os.path.basename(pdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de BASF_sustainability_report_2024.pdf...\n",
      "  - 2064 chunks cr√©√©s\n",
      "Traitement de Bayer_sustainability_report_2024.pdf...\n",
      "Erreur avec Bayer_sustainability_report_2024.pdf: PyCryptodome is required for AES algorithm\n",
      "Traitement de Cargill_sustainability_report_2024.pdf...\n",
      "  - 968 chunks cr√©√©s\n",
      "Traitement de CK_Hutchinson _sustainability_report_2024.pdf...\n",
      "  - 1119 chunks cr√©√©s\n",
      "Traitement de Honeywell_sustainability_report_2024.pdf...\n",
      "  - 621 chunks cr√©√©s\n",
      "Traitement de Merck_sustainability_report_2024.pdf...\n",
      "  - 1465 chunks cr√©√©s\n",
      "Traitement de Microsoft_sustainability_report_2024.pdf...\n",
      "  - 1115 chunks cr√©√©s\n",
      "Traitement de Qualcomm_sustainability_report_2023.pdf...\n",
      "  - 831 chunks cr√©√©s\n",
      "Traitement de Shell_sustainability_report_2023.pdf...\n",
      "  - 1177 chunks cr√©√©s\n",
      "Traitement de Thai_Oil_sustainability_report_2023.pdf...\n",
      "  - 803 chunks cr√©√©s\n",
      "Traitement de Veolia_sustainability_report_2024.pdf...\n",
      "  - 392 chunks cr√©√©s\n",
      "Traitement de Verizon_sustainability_report_2023.pdf...\n",
      "  - 924 chunks cr√©√©s\n",
      "Traitement de Walmart_sustainability_report_2023.pdf...\n",
      "  - 285 chunks cr√©√©s\n",
      "Total : 11764 chunks cr√©√©s\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.schema import Document\n",
    "import PyPDF2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Initialiser le text splitter pour un chunking plus fin et hi√©rarchique\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=350,  # Taille r√©duite comme demand√©\n",
    "    chunk_overlap=50,  # Chevauchement adapt√© √† la nouvelle taille\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # S√©parateurs plus pr√©cis\n",
    ")\n",
    "\n",
    "pdf_folder = r\"C:\\Users\\Mazen ISMAIL\\Downloads\\Rag project\\Data\"\n",
    "pdf_files = glob.glob(os.path.join(pdf_folder, \"*.pdf\"))\n",
    "\n",
    "# Charger et d√©couper les PDF un par un avec support des tableaux et images\n",
    "all_chunks = []\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        print(f\"Traitement de {os.path.basename(pdf_file)}...\")\n",
    "        \n",
    "        # Utiliser PyPDF2 pour extraire le texte\n",
    "        with open(pdf_file, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "            \n",
    "            # M√©tadonn√©es du document\n",
    "            doc_metadata = {\n",
    "                \"source\": pdf_file,\n",
    "                \"title\": os.path.basename(pdf_file),\n",
    "                \"total_pages\": len(reader.pages)\n",
    "            }\n",
    "            \n",
    "            for page_num, page in enumerate(reader.pages):\n",
    "                # Extraire le texte\n",
    "                text = page.extract_text() or \"\"\n",
    "                \n",
    "                # Combiner avec des marqueurs de structure\n",
    "                page_content = f\"# Page {page_num+1}\\n{text}\"\n",
    "                pdf_text += page_content\n",
    "        \n",
    "        # D√©couper avec pr√©servation de la structure\n",
    "        try:\n",
    "            header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n",
    "                (\"#\", \"header1\"),\n",
    "                (\"##\", \"header2\"),\n",
    "            ])\n",
    "            md_header_splits = header_splitter.split_text(pdf_text)\n",
    "            \n",
    "            # D√©couper en chunks tout en pr√©servant les m√©tadonn√©es hi√©rarchiques\n",
    "            chunks = []\n",
    "            for split in md_header_splits:\n",
    "                # Pr√©server le contexte hi√©rarchique dans les m√©tadonn√©es\n",
    "                split_metadata = {**doc_metadata, **split.metadata}\n",
    "                # D√©couper davantage si n√©cessaire\n",
    "                smaller_chunks = text_splitter.split_text(split.page_content)\n",
    "                # Cr√©er des Documents avec contexte pr√©serv√©\n",
    "                for chunk in smaller_chunks:\n",
    "                    chunks.append(Document(page_content=chunk, metadata=split_metadata))\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du d√©coupage hi√©rarchique: {e}\")\n",
    "            # Fallback au d√©coupage simple\n",
    "            chunks = []\n",
    "            with open(pdf_file, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for i, page in enumerate(reader.pages):\n",
    "                    text = page.extract_text() or \"\"\n",
    "                    page_doc = Document(\n",
    "                        page_content=text,\n",
    "                        metadata={\"source\": pdf_file, \"page\": i+1}\n",
    "                    )\n",
    "                    page_chunks = text_splitter.split_documents([page_doc])\n",
    "                    chunks.extend(page_chunks)\n",
    "        \n",
    "        all_chunks.extend(chunks)\n",
    "        print(f\"  - {len(chunks)} chunks cr√©√©s\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec {os.path.basename(pdf_file)}: {e}\")\n",
    "\n",
    "print(f\"Total : {len(all_chunks)} chunks cr√©√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding cr√©√© avec succ√®s - Dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"OpenAIKey.env\")\n",
    "\n",
    "# Cr√©er l'instance d'embeddings\n",
    "try:\n",
    "    # Pour GPT-4o mini, utilisez le mod√®le d'embedding appropri√© \n",
    "    # (text-embedding-3-small est un bon choix √©conomique)\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    # Test pour v√©rifier que √ßa fonctionne\n",
    "    if all_chunks:\n",
    "        test_text = all_chunks[0].page_content[:100]\n",
    "        test_embedding = embeddings.embed_query(test_text)\n",
    "        print(f\"‚úÖ Embedding cr√©√© avec succ√®s - Dimension: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de la cr√©ation des embeddings: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cr√©ation des embeddings pour tous les chunks...\n",
      "Traitement du lot 1/236...\n",
      "Traitement du lot 2/236...\n",
      "Traitement du lot 3/236...\n",
      "Traitement du lot 4/236...\n",
      "Traitement du lot 5/236...\n",
      "Traitement du lot 6/236...\n",
      "Traitement du lot 7/236...\n",
      "Traitement du lot 8/236...\n",
      "Traitement du lot 9/236...\n",
      "Traitement du lot 10/236...\n",
      "Traitement du lot 11/236...\n",
      "Traitement du lot 12/236...\n",
      "Traitement du lot 13/236...\n",
      "Traitement du lot 14/236...\n",
      "Traitement du lot 15/236...\n",
      "Traitement du lot 16/236...\n",
      "Traitement du lot 17/236...\n",
      "Traitement du lot 18/236...\n",
      "Traitement du lot 19/236...\n",
      "Traitement du lot 20/236...\n",
      "Traitement du lot 21/236...\n",
      "Traitement du lot 22/236...\n",
      "Traitement du lot 23/236...\n",
      "Traitement du lot 24/236...\n",
      "Traitement du lot 25/236...\n",
      "Traitement du lot 26/236...\n",
      "Traitement du lot 27/236...\n",
      "Traitement du lot 28/236...\n",
      "Traitement du lot 29/236...\n",
      "Traitement du lot 30/236...\n",
      "Traitement du lot 31/236...\n",
      "Traitement du lot 32/236...\n",
      "Traitement du lot 33/236...\n",
      "Traitement du lot 34/236...\n",
      "Traitement du lot 35/236...\n",
      "Traitement du lot 36/236...\n",
      "Traitement du lot 37/236...\n",
      "Traitement du lot 38/236...\n",
      "Traitement du lot 39/236...\n",
      "Traitement du lot 40/236...\n",
      "Traitement du lot 41/236...\n",
      "Traitement du lot 42/236...\n",
      "Traitement du lot 43/236...\n",
      "Traitement du lot 44/236...\n",
      "Traitement du lot 45/236...\n",
      "Traitement du lot 46/236...\n",
      "Traitement du lot 47/236...\n",
      "Traitement du lot 48/236...\n",
      "Traitement du lot 49/236...\n",
      "Traitement du lot 50/236...\n",
      "Traitement du lot 51/236...\n",
      "Traitement du lot 52/236...\n",
      "Traitement du lot 53/236...\n",
      "Traitement du lot 54/236...\n",
      "Traitement du lot 55/236...\n",
      "Traitement du lot 56/236...\n",
      "Traitement du lot 57/236...\n",
      "Traitement du lot 58/236...\n",
      "Traitement du lot 59/236...\n",
      "Traitement du lot 60/236...\n",
      "Traitement du lot 61/236...\n",
      "Traitement du lot 62/236...\n",
      "Traitement du lot 63/236...\n",
      "Traitement du lot 64/236...\n",
      "Traitement du lot 65/236...\n",
      "Traitement du lot 66/236...\n",
      "Traitement du lot 67/236...\n",
      "Traitement du lot 68/236...\n",
      "Traitement du lot 69/236...\n",
      "Traitement du lot 70/236...\n",
      "Traitement du lot 71/236...\n",
      "Traitement du lot 72/236...\n",
      "Traitement du lot 73/236...\n",
      "Traitement du lot 74/236...\n",
      "Traitement du lot 75/236...\n",
      "Traitement du lot 76/236...\n",
      "Traitement du lot 77/236...\n",
      "Traitement du lot 78/236...\n",
      "Traitement du lot 79/236...\n",
      "Traitement du lot 80/236...\n",
      "Traitement du lot 81/236...\n",
      "Traitement du lot 82/236...\n",
      "Traitement du lot 83/236...\n",
      "Traitement du lot 84/236...\n",
      "Traitement du lot 85/236...\n",
      "Traitement du lot 86/236...\n",
      "Traitement du lot 87/236...\n",
      "Traitement du lot 88/236...\n",
      "Traitement du lot 89/236...\n",
      "Traitement du lot 90/236...\n",
      "Traitement du lot 91/236...\n",
      "Traitement du lot 92/236...\n",
      "Traitement du lot 93/236...\n",
      "Traitement du lot 94/236...\n",
      "Traitement du lot 95/236...\n",
      "Traitement du lot 96/236...\n",
      "Traitement du lot 97/236...\n",
      "Traitement du lot 98/236...\n",
      "Traitement du lot 99/236...\n",
      "Traitement du lot 100/236...\n",
      "Traitement du lot 101/236...\n",
      "Traitement du lot 102/236...\n",
      "Traitement du lot 103/236...\n",
      "Traitement du lot 104/236...\n",
      "Traitement du lot 105/236...\n",
      "Traitement du lot 106/236...\n",
      "Traitement du lot 107/236...\n",
      "Traitement du lot 108/236...\n",
      "Traitement du lot 109/236...\n",
      "Traitement du lot 110/236...\n",
      "Traitement du lot 111/236...\n",
      "Traitement du lot 112/236...\n",
      "Traitement du lot 113/236...\n",
      "Traitement du lot 114/236...\n",
      "Traitement du lot 115/236...\n",
      "Traitement du lot 116/236...\n",
      "Traitement du lot 117/236...\n",
      "Traitement du lot 118/236...\n",
      "Traitement du lot 119/236...\n",
      "Traitement du lot 120/236...\n",
      "Traitement du lot 121/236...\n",
      "Traitement du lot 122/236...\n",
      "Traitement du lot 123/236...\n",
      "Traitement du lot 124/236...\n",
      "Traitement du lot 125/236...\n",
      "Traitement du lot 126/236...\n",
      "Traitement du lot 127/236...\n",
      "Traitement du lot 128/236...\n",
      "Traitement du lot 129/236...\n",
      "Traitement du lot 130/236...\n",
      "Traitement du lot 131/236...\n",
      "Traitement du lot 132/236...\n",
      "Traitement du lot 133/236...\n",
      "Traitement du lot 134/236...\n",
      "Traitement du lot 135/236...\n",
      "Traitement du lot 136/236...\n",
      "Traitement du lot 137/236...\n",
      "Traitement du lot 138/236...\n",
      "Traitement du lot 139/236...\n",
      "Traitement du lot 140/236...\n",
      "Traitement du lot 141/236...\n",
      "Traitement du lot 142/236...\n",
      "Traitement du lot 143/236...\n",
      "Traitement du lot 144/236...\n",
      "Traitement du lot 145/236...\n",
      "Traitement du lot 146/236...\n",
      "Traitement du lot 147/236...\n",
      "Traitement du lot 148/236...\n",
      "Traitement du lot 149/236...\n",
      "Traitement du lot 150/236...\n",
      "Traitement du lot 151/236...\n",
      "Traitement du lot 152/236...\n",
      "Traitement du lot 153/236...\n",
      "Traitement du lot 154/236...\n",
      "Traitement du lot 155/236...\n",
      "Traitement du lot 156/236...\n",
      "Traitement du lot 157/236...\n",
      "Traitement du lot 158/236...\n",
      "Traitement du lot 159/236...\n",
      "Traitement du lot 160/236...\n",
      "Traitement du lot 161/236...\n",
      "Traitement du lot 162/236...\n",
      "Traitement du lot 163/236...\n",
      "Traitement du lot 164/236...\n",
      "Traitement du lot 165/236...\n",
      "Traitement du lot 166/236...\n",
      "Traitement du lot 167/236...\n",
      "Traitement du lot 168/236...\n",
      "Traitement du lot 169/236...\n",
      "Traitement du lot 170/236...\n",
      "Traitement du lot 171/236...\n",
      "Traitement du lot 172/236...\n",
      "Traitement du lot 173/236...\n",
      "Traitement du lot 174/236...\n",
      "Traitement du lot 175/236...\n",
      "Traitement du lot 176/236...\n",
      "Traitement du lot 177/236...\n",
      "Traitement du lot 178/236...\n",
      "Traitement du lot 179/236...\n",
      "Traitement du lot 180/236...\n",
      "Traitement du lot 181/236...\n",
      "Traitement du lot 182/236...\n",
      "Traitement du lot 183/236...\n",
      "Traitement du lot 184/236...\n",
      "Traitement du lot 185/236...\n",
      "Traitement du lot 186/236...\n",
      "Traitement du lot 187/236...\n",
      "Traitement du lot 188/236...\n",
      "Traitement du lot 189/236...\n",
      "Traitement du lot 190/236...\n",
      "Traitement du lot 191/236...\n",
      "Traitement du lot 192/236...\n",
      "Traitement du lot 193/236...\n",
      "Traitement du lot 194/236...\n",
      "Traitement du lot 195/236...\n",
      "Traitement du lot 196/236...\n",
      "Traitement du lot 197/236...\n",
      "Traitement du lot 198/236...\n",
      "Traitement du lot 199/236...\n",
      "Traitement du lot 200/236...\n",
      "Traitement du lot 201/236...\n",
      "Traitement du lot 202/236...\n",
      "Traitement du lot 203/236...\n",
      "Traitement du lot 204/236...\n",
      "Traitement du lot 205/236...\n",
      "Traitement du lot 206/236...\n",
      "Traitement du lot 207/236...\n",
      "Traitement du lot 208/236...\n",
      "Traitement du lot 209/236...\n",
      "Traitement du lot 210/236...\n",
      "Traitement du lot 211/236...\n",
      "Traitement du lot 212/236...\n",
      "Traitement du lot 213/236...\n",
      "Traitement du lot 214/236...\n",
      "Traitement du lot 215/236...\n",
      "Traitement du lot 216/236...\n",
      "Traitement du lot 217/236...\n",
      "Traitement du lot 218/236...\n",
      "Traitement du lot 219/236...\n",
      "Traitement du lot 220/236...\n",
      "Traitement du lot 221/236...\n",
      "Traitement du lot 222/236...\n",
      "Traitement du lot 223/236...\n",
      "Traitement du lot 224/236...\n",
      "Traitement du lot 225/236...\n",
      "Traitement du lot 226/236...\n",
      "Traitement du lot 227/236...\n",
      "Traitement du lot 228/236...\n",
      "Traitement du lot 229/236...\n",
      "Traitement du lot 230/236...\n",
      "Traitement du lot 231/236...\n",
      "Traitement du lot 232/236...\n",
      "Traitement du lot 233/236...\n",
      "Traitement du lot 234/236...\n",
      "Traitement du lot 235/236...\n",
      "Traitement du lot 236/236...\n",
      "‚úÖ Embeddings cr√©√©s pour 11764 chunks sur 11764\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour traiter les chunks par lots\n",
    "def process_chunks_in_batches(chunks, batch_size=100):\n",
    "    \"\"\"Traite les chunks par lots pour √©viter les limitations d'API\"\"\"\n",
    "    total_chunks = len(chunks)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, total_chunks, batch_size):\n",
    "        batch = chunks[i:min(i + batch_size, total_chunks)]\n",
    "        print(f\"Traitement du lot {i//batch_size + 1}/{(total_chunks-1)//batch_size + 1}...\")\n",
    "        \n",
    "        # Extraire le texte de chaque chunk pour l'embedding\n",
    "        texts = [chunk.page_content for chunk in batch]\n",
    "        \n",
    "        try:\n",
    "            # Cr√©er les embeddings pour ce lot\n",
    "            batch_embeddings = embeddings.embed_documents(texts)\n",
    "            \n",
    "            # Stocker les r√©sultats (texte, embedding, m√©tadonn√©es)\n",
    "            for j, embedding_vector in enumerate(batch_embeddings):\n",
    "                chunk_data = {\n",
    "                    \"text\": batch[j].page_content,\n",
    "                    \"embedding\": embedding_vector,\n",
    "                    \"metadata\": batch[j].metadata\n",
    "                }\n",
    "                results.append(chunk_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement du lot {i//batch_size + 1}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Traiter tous les chunks\n",
    "print(\"Cr√©ation des embeddings pour tous les chunks...\")\n",
    "embedded_chunks = process_chunks_in_batches(all_chunks, batch_size=50)\n",
    "print(f\"‚úÖ Embeddings cr√©√©s pour {len(embedded_chunks)} chunks sur {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucun index FAISS existant trouv√©.\n",
      "Cr√©ation de l'index FAISS...\n",
      "Sauvegarde de l'index FAISS dans C:\\Users\\Mazen ISMAIL\\Downloads\\Rag project\\faiss_index...\n",
      "‚úÖ Index FAISS cr√©√© et sauvegard√© avec succ√®s!\n",
      "Test de recherche pour: 'Qu'est-ce que le RAG?'\n",
      "Trouv√© 2 r√©sultats pertinents.\n",
      "Exemple de r√©sultat: procedure (e-Rapid Incident Report). The aim is to identify risks at an early stage and, if necessary,\n",
      "initiate appropriate remedial and communication...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Cr√©er un r√©pertoire pour stocker l'index FAISS si n√©cessaire\n",
    "index_folder = os.path.join(os.path.dirname(pdf_folder), \"faiss_index\")\n",
    "os.makedirs(index_folder, exist_ok=True)\n",
    "\n",
    "# Chemin du fichier de sauvegarde\n",
    "index_file_path = os.path.join(index_folder, \"pdf_embeddings_index.faiss\")\n",
    "index_pkl_path = os.path.join(index_folder, \"pdf_embeddings_index.pkl\")\n",
    "\n",
    "# Fonction pour cr√©er et sauvegarder l'index FAISS\n",
    "def create_and_save_faiss_index(embedded_chunks, embeddings_model):\n",
    "    # Pr√©parer les donn√©es pour FAISS\n",
    "    texts = [item[\"text\"] for item in embedded_chunks]\n",
    "    embeddings_list = [item[\"embedding\"] for item in embedded_chunks]\n",
    "    metadatas = [item[\"metadata\"] for item in embedded_chunks]\n",
    "    \n",
    "    # Cr√©er l'index FAISS\n",
    "    print(\"Cr√©ation de l'index FAISS...\")\n",
    "    vector_store = FAISS.from_embeddings(\n",
    "        text_embeddings=list(zip(texts, embeddings_list)),\n",
    "        embedding=embeddings_model,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder l'index\n",
    "    print(f\"Sauvegarde de l'index FAISS dans {index_folder}...\")\n",
    "    vector_store.save_local(index_folder)\n",
    "    \n",
    "    print(\"‚úÖ Index FAISS cr√©√© et sauvegard√© avec succ√®s!\")\n",
    "    return vector_store\n",
    "\n",
    "# Fonction pour charger l'index FAISS s'il existe d√©j√†\n",
    "def load_faiss_index(embeddings_model):\n",
    "    if os.path.exists(os.path.join(index_folder, \"index.faiss\")):\n",
    "        print(\"Chargement de l'index FAISS existant...\")\n",
    "        try:\n",
    "            vector_store = FAISS.load_local(index_folder, embeddings_model)\n",
    "            print(\"‚úÖ Index FAISS charg√© avec succ√®s!\")\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de l'index: {e}\")\n",
    "    \n",
    "    print(\"‚ùå Aucun index FAISS existant trouv√©.\")\n",
    "    return None\n",
    "\n",
    "# Cr√©er ou charger l'index FAISS\n",
    "vector_store = load_faiss_index(embeddings)\n",
    "if vector_store is None:\n",
    "    vector_store = create_and_save_faiss_index(embedded_chunks, embeddings)\n",
    "\n",
    "# V√©rifier que l'index fonctionne\n",
    "test_query = \"Qu'est-ce que le RAG?\"\n",
    "print(f\"Test de recherche pour: '{test_query}'\")\n",
    "test_results = vector_store.similarity_search(test_query, k=2)\n",
    "print(f\"Trouv√© {len(test_results)} r√©sultats pertinents.\")\n",
    "if test_results:\n",
    "    print(f\"Exemple de r√©sultat: {test_results[0].page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction modifi√©e pour charger l'index FAISS avec l'option de s√©curit√© activ√©e\n",
    "def load_faiss_index(embeddings_model):\n",
    "    if os.path.exists(os.path.join(index_folder, \"index.faiss\")):\n",
    "        print(\"Chargement de l'index FAISS existant...\")\n",
    "        try:\n",
    "            vector_store = FAISS.load_local(\n",
    "                index_folder, \n",
    "                embeddings_model,\n",
    "                allow_dangerous_deserialization=True  # Ajout de cette option\n",
    "            )\n",
    "            print(\"‚úÖ Index FAISS charg√© avec succ√®s!\")\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de l'index: {e}\")\n",
    "    \n",
    "    print(\"‚ùå Aucun index FAISS existant trouv√©.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 20:53:11.057 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.schema import Document\n",
    "import fitz  # PyMuPDF\n",
    "import tempfile\n",
    "import shutil\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement des variables d'environnement\n",
    "load_dotenv(dotenv_path=\"OpenAIKey.env\")\n",
    "\n",
    "# Configuration de la page Streamlit avec th√®me\n",
    "st.set_page_config(\n",
    "    page_title=\"Assistant RAG pour PDF\",\n",
    "    page_icon=\"üìö\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 20:53:16.738 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:17.028 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Mazen ISMAIL\\env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-18 20:53:17.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliquer des styles CSS am√©lior√©s\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    /* Styles pour les titres et sous-titres */\n",
    "    .main-header {\n",
    "        font-size: 2.5rem;\n",
    "        font-weight: 700;\n",
    "        color: #1E88E5;\n",
    "        margin-bottom: 1.5rem;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    .sub-header {\n",
    "        font-size: 1.8rem;\n",
    "        font-weight: 600;\n",
    "        color: #0D47A1;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        margin-top: 1.5rem;\n",
    "        margin-bottom: 1rem;\n",
    "    }\n",
    "    \n",
    "    /* Box d'information */\n",
    "    .info-box {\n",
    "        background-color: #E3F2FD;\n",
    "        padding: 1.2rem;\n",
    "        border-radius: 0.7rem;\n",
    "        margin-bottom: 1.5rem;\n",
    "        border-left: 5px solid #1E88E5;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    \n",
    "    /* Conteneur de r√©sultat */\n",
    "    .result-container {\n",
    "        background-color: #FAFAFA;\n",
    "        padding: 1.8rem;\n",
    "        border-radius: 0.7rem;\n",
    "        border-left: 7px solid #1E88E5;\n",
    "        margin-top: 1.5rem;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        line-height: 1.6;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);\n",
    "    }\n",
    "    \n",
    "    /* Titre de source */\n",
    "    .source-title {\n",
    "        font-weight: 600;\n",
    "        color: #0D47A1;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    \n",
    "    /* Section de barre lat√©rale */\n",
    "    .sidebar-section {\n",
    "        background-color: #F5F5F5;\n",
    "        padding: 1.2rem;\n",
    "        border-radius: 0.7rem;\n",
    "        margin-bottom: 1.5rem;\n",
    "        border-left: 4px solid #1E88E5;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    \n",
    "    /* Style pour les tabs */\n",
    "    .stTabs [data-baseweb=\"tab-list\"] {\n",
    "        gap: 2rem;\n",
    "    }\n",
    "    \n",
    "    .stTabs [data-baseweb=\"tab\"] {\n",
    "        height: 3rem;\n",
    "        white-space: pre-wrap;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        font-weight: 500;\n",
    "    }\n",
    "    \n",
    "    /* Tableaux de donn√©es */\n",
    "    .dataframe-container {\n",
    "        border-radius: 0.7rem;\n",
    "        overflow: hidden;\n",
    "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);\n",
    "        margin-top: 1rem;\n",
    "    }\n",
    "    \n",
    "    /* Boutons */\n",
    "    .stButton > button {\n",
    "        font-weight: 600;\n",
    "        padding: 0.6rem 1.2rem;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    \n",
    "    /* Uniformisation des polices pour tout le contenu */\n",
    "    body, .stTextInput label, .stTextInput input, .stTextArea label, .stTextArea textarea,\n",
    "    .stSelectbox label, .stSelectbox select, .stSlider label, p, div, span {\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
    "    }\n",
    "    \n",
    "    /* Style pour les m√©triques */\n",
    "    .metric-container {\n",
    "        background-color: #F5F5F5;\n",
    "        padding: 1rem;\n",
    "        border-radius: 0.5rem;\n",
    "        text-align: center;\n",
    "        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);\n",
    "    }\n",
    "    \n",
    "    .metric-value {\n",
    "        font-size: 1.8rem;\n",
    "        font-weight: 700;\n",
    "        color: #1E88E5;\n",
    "    }\n",
    "    \n",
    "    .metric-label {\n",
    "        font-size: 1rem;\n",
    "        color: #555;\n",
    "        margin-top: 0.3rem;\n",
    "    }\n",
    "    \n",
    "    /* Style pour les onglets principaux */\n",
    "    .main-tabs {\n",
    "        margin-top: 1.5rem;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 21:06:45.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:06:45.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers l'index FAISS pr√©existant\n",
    "index_folder = r\"C:\\Users\\Mazen ISMAIL\\Downloads\\Rag project\\faiss_index\"\n",
    "\n",
    "# Titre et description\n",
    "st.markdown('<div class=\"main-header\">üìö Assistant RAG pour PDF</div>', unsafe_allow_html=True)\n",
    "st.markdown(\"\"\"\n",
    "<div class=\"info-box\">\n",
    "Cet assistant utilise la technologie <b>RAG (Retrieval Augmented Generation)</b> pour r√©pondre √† vos questions\n",
    "sur les documents PDF. Gr√¢ce √† l'extraction s√©mantique avanc√©e, il peut:\n",
    "<ul>\n",
    "    <li>Pr√©server la structure des documents, y compris les tableaux</li>\n",
    "    <li>Agr√©ger l'information provenant de plusieurs sources</li>\n",
    "    <li>Filtrer les r√©sultats non pertinents gr√¢ce √† la similarit√© cosine</li>\n",
    "</ul>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Cr√©ation des onglets principaux\n",
    "tab1, tab2 = st.tabs([\"üîç **Recherche**\", \"üì§ **Gestion des documents**\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 20:53:31.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:31.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour charger l'index FAISS existant avec cache\n",
    "@st.cache_resource\n",
    "def load_vector_store():\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        vector_store = FAISS.load_local(\n",
    "            index_folder, \n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        return vector_store, True\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erreur lors du chargement de l'index FAISS: {e}\")\n",
    "        return None, False\n",
    "\n",
    "# Charger l'index au d√©marrage\n",
    "vector_store, success = load_vector_store()\n",
    "\n",
    "# Fonction pour obtenir les sources disponibles\n",
    "def get_all_sources(vector_store):\n",
    "    try:\n",
    "        all_docs = vector_store.docstore._dict.values()\n",
    "        sources = set()\n",
    "        for doc in all_docs:\n",
    "            source = os.path.basename(doc.metadata.get('source', ''))\n",
    "            if source:\n",
    "                sources.add(source)\n",
    "        return ['Tous les documents'] + sorted(list(sources))\n",
    "    except:\n",
    "        return ['Tous les documents']\n",
    "\n",
    "# Liste √©tendue des mod√®les OpenAI\n",
    "openai_models = [\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4.1\",\n",
    "    \"o4-mini\",          # tout nouveau, successeur d‚Äôo3-mini :contentReference[oaicite:5]{index=5}\n",
    "    \"o3\",               # grand mod√®le raisonnement :contentReference[oaicite:6]{index=6}\n",
    "    \"o3-mini\",\n",
    "    \"text-embedding-3-small\",\n",
    "    \"text-embedding-3-large\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 20:53:36.510 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.510 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.516 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.533 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.535 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.538 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.539 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.540 Session state does not function when running a script without `streamlit run`\n",
      "2025-05-18 20:53:36.540 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.540 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.540 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.542 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.542 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.544 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.544 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.544 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.546 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.546 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.552 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.553 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.553 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.553 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.554 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.557 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.557 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.559 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.562 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.562 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.563 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.567 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.569 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.569 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.573 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.573 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.576 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.576 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.577 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.577 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.577 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 20:53:36.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Onglet 1: Recherche\n",
    "with tab1:\n",
    "    # Param√®tres dans la barre lat√©rale\n",
    "    with st.sidebar:\n",
    "        st.markdown('<div class=\"sidebar-section\">', unsafe_allow_html=True)\n",
    "        st.header(\"‚öôÔ∏è Param√®tres\")\n",
    "\n",
    "        # Nombre de chunks et seuil de similarit√©\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            k_value = st.slider(\"Chunks √† r√©cup√©rer\", 1, 15, 5)\n",
    "        with col2:\n",
    "            similarity_threshold = st.slider(\"Seuil similarit√©\", 0.0, 1.0, 0.7, 0.05)\n",
    "\n",
    "        # Temp√©rature du mod√®le\n",
    "        temperature = st.slider(\"Temp√©rature du LLM\", 0.0, 1.0, 0.1, 0.1, \n",
    "                              help=\"Contr√¥le la cr√©ativit√© du mod√®le. Plus √©lev√© = plus cr√©atif mais moins pr√©cis.\")\n",
    "\n",
    "        # Choix du mod√®le (liste √©tendue)\n",
    "        llm_model = st.selectbox(\n",
    "            \"Mod√®le LLM\",\n",
    "            openai_models,\n",
    "            index=0,\n",
    "            help=\"S√©lectionnez le mod√®le OpenAI √† utiliser pour la g√©n√©ration de r√©ponses.\"\n",
    "        )\n",
    "\n",
    "        # Option pour l'agr√©gation\n",
    "        enable_aggregation = st.checkbox(\"Activer l'agr√©gation avanc√©e\", True,\n",
    "                                      help=\"Utilise map_reduce pour synth√©tiser l'information de plusieurs sources\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "        # Filtrage par sources si l'index est charg√©\n",
    "        if success:\n",
    "            st.markdown('<div class=\"sidebar-section\">', unsafe_allow_html=True)\n",
    "            st.header(\"üîç Filtrage\")\n",
    "            all_sources = get_all_sources(vector_store)\n",
    "            selected_sources = st.multiselect(\n",
    "                \"Filtrer par documents\",\n",
    "                options=all_sources,\n",
    "                default=[\"Tous les documents\"]\n",
    "            )\n",
    "            st.markdown('</div>', unsafe_allow_html=True)\n",
    "        else:\n",
    "            selected_sources = [\"Tous les documents\"]\n",
    "\n",
    "    # Interface utilisateur du chat\n",
    "    st.markdown('<div class=\"sub-header\">üí¨ Posez votre question</div>', unsafe_allow_html=True)\n",
    "\n",
    "    # Zone de saisie pour la question\n",
    "    query = st.text_area(\"Votre question sur les documents:\", height=100)\n",
    "\n",
    "    # Ajouter des exemples de questions\n",
    "    with st.expander(\"Exemples de questions\"):\n",
    "        example_queries = [\n",
    "            \"Qu'est-ce que le RAG?\",\n",
    "            \"Quels sont les avantages des syst√®mes RAG par rapport aux mod√®les classiques?\",\n",
    "            \"Comment fonctionnent les embeddings dans un syst√®me RAG?\",\n",
    "            \"Quelles sont les sources d'√©nergies renouvelables mentionn√©es dans le document?\",\n",
    "            \"Quel est le plan d'investissement de TotalEnergies pour 2023-2025?\"\n",
    "        ]\n",
    "        cols = st.columns(3)\n",
    "        for i, example in enumerate(example_queries):\n",
    "            if cols[i % 3].button(example, key=f\"example_{i}\"):\n",
    "                query = example\n",
    "\n",
    "    # Option pour afficher la visualisation\n",
    "    show_visualization = st.checkbox(\"Afficher la visualisation des chunks\", False)\n",
    "\n",
    "    # Bouton pour soumettre la requ√™te\n",
    "    submit_button = st.button(\"üîç Rechercher\", type=\"primary\", use_container_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour interroger le RAG avec similarit√© cosine am√©lior√©e\n",
    "def query_rag(query):\n",
    "    # Cr√©er le LLM\n",
    "    llm = ChatOpenAI(\n",
    "        model=llm_model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    # Cr√©er le retriever avec seuil de similarit√©\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": k_value,\n",
    "            \"score_threshold\": similarity_threshold\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Filtrer par source si sp√©cifi√©\n",
    "    if selected_sources and 'Tous les documents' not in selected_sources:\n",
    "        # Cr√©er une fonction de filtrage pour les sources s√©lectionn√©es\n",
    "        def filter_by_sources(docs):\n",
    "            return [\n",
    "                doc for doc in docs \n",
    "                if os.path.basename(doc.metadata.get('source', '')) in selected_sources\n",
    "            ]\n",
    "        \n",
    "        # Appliquer le filtre au retriever\n",
    "        retriever.search_kwargs[\"filter_fn\"] = filter_by_sources\n",
    "    \n",
    "    # Template de prompt am√©lior√© pour la cha√Æne stuff\n",
    "    prompt_template = \"\"\"\n",
    "    Tu es un assistant d'information sp√©cialis√© qui aide √† r√©pondre aux questions bas√©es sur des documents PDF.\n",
    "    \n",
    "    Utilise UNIQUEMENT les informations fournies dans le contexte ci-dessous pour r√©pondre.\n",
    "    Si l'information n'est pas pr√©sente dans le contexte, dis simplement \"Je ne trouve pas cette information dans les documents fournis.\"\n",
    "    Ne fabrique pas de r√©ponse.\n",
    "    \n",
    "    IMPORTANT: \n",
    "    - Synth√©tise les informations provenant de sources multiples si n√©cessaire.\n",
    "    - Si des informations contradictoires apparaissent, signale-le et pr√©sente les diff√©rentes perspectives.\n",
    "    - Pour les informations num√©riques ou factuelles, cite pr√©cis√©ment les sources avec le num√©ro de page.\n",
    "    - Si des tableaux sont mentionn√©s dans les chunks, pr√©sente les donn√©es sous forme structur√©e.\n",
    "    - Mentionne toujours le num√©ro de page exact dans tes citations.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXTE:\n",
    "    {context}\n",
    "    \n",
    "    R√âPONSE (synth√©tise les informations de mani√®re coh√©rente, avec citations des sources et num√©ros de page):\n",
    "    \"\"\"\n",
    "    \n",
    "    # Templates sp√©cifiques pour map-reduce\n",
    "    map_template = \"\"\"\n",
    "    Tu es un assistant d'information sp√©cialis√© qui aide √† r√©pondre aux questions bas√©es sur des documents PDF.\n",
    "    \n",
    "    R√©sume le contexte suivant pour r√©pondre √† la question.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXTE:\n",
    "    {context}\n",
    "    \n",
    "    R√âSUM√â (ne r√©ponds pas encore √† la question, fais uniquement un r√©sum√© des informations pertinentes):\n",
    "    \"\"\"\n",
    "    \n",
    "    reduce_template = \"\"\"\n",
    "    Tu es un assistant d'information sp√©cialis√© qui aide √† r√©pondre aux questions bas√©es sur des documents PDF.\n",
    "    \n",
    "    Utilise UNIQUEMENT les informations fournies dans les r√©sum√©s ci-dessous pour r√©pondre.\n",
    "    Si l'information n'est pas pr√©sente dans les r√©sum√©s, dis simplement \"Je ne trouve pas cette information dans les documents fournis.\"\n",
    "    Ne fabrique pas de r√©ponse.\n",
    "    \n",
    "    IMPORTANT: \n",
    "    - Synth√©tise les informations provenant de sources multiples si n√©cessaire.\n",
    "    - Si des informations contradictoires apparaissent, signale-le et pr√©sente les diff√©rentes perspectives.\n",
    "    - Pour les informations num√©riques ou factuelles, cite pr√©cis√©ment les sources, si mentionn√©es dans les r√©sum√©s.\n",
    "    - Si des tableaux sont mentionn√©s, pr√©sente les donn√©es sous forme structur√©e.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    R√âSUM√âS:\n",
    "    {summaries}\n",
    "    \n",
    "    R√âPONSE (synth√©tise les informations de mani√®re coh√©rente, avec citations des sources si disponibles):\n",
    "    \"\"\"\n",
    "    \n",
    "    STUFF_PROMPT = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    MAP_PROMPT = PromptTemplate(\n",
    "        template=map_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    REDUCE_PROMPT = PromptTemplate(\n",
    "        template=reduce_template,\n",
    "        input_variables=[\"summaries\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # Cr√©er la cha√Æne RAG avec capacit√© d'agr√©gation\n",
    "    if enable_aggregation:\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"map_reduce\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\n",
    "                \"question_prompt\": MAP_PROMPT,\n",
    "                \"combine_prompt\": REDUCE_PROMPT\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\"prompt\": STUFF_PROMPT}\n",
    "        )\n",
    "    \n",
    "    # Ex√©cuter la requ√™te\n",
    "    result = qa_chain({\"query\": query})\n",
    "    \n",
    "    return {\n",
    "        \"answer\": result[\"result\"],\n",
    "        \"source_docs\": result[\"source_documents\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la requ√™te si une question est pos√©e et le bouton est cliqu√©\n",
    "if query and submit_button:\n",
    "    if success:\n",
    "        with st.status(\"üîç Recherche d'informations dans les documents...\") as status:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Ex√©cuter la requ√™te\n",
    "                result = query_rag(query)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                status.update(label=\"‚úÖ Recherche termin√©e!\", state=\"complete\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Erreur lors de la recherche: {str(e)}\")\n",
    "                import traceback\n",
    "                st.error(traceback.format_exc())\n",
    "                st.stop()\n",
    "            \n",
    "            # Afficher la r√©ponse\n",
    "            st.markdown('<div class=\"sub-header\">üìù R√©ponse</div>', unsafe_allow_html=True)\n",
    "            st.markdown(f'<div class=\"result-container\">{result[\"answer\"]}</div>', unsafe_allow_html=True)\n",
    "            \n",
    "            # Afficher des m√©triques\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{elapsed_time:.2f}s</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Temps de r√©ponse</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "            with col2:\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{len(set([os.path.basename(doc.metadata.get(\"source\", \"\")) for doc in result[\"source_docs\"]]))}</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Documents utilis√©s</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "            with col3:\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{len(result[\"source_docs\"])}</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Chunks utilis√©s</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "            \n",
    "            # Afficher les sources\n",
    "            st.markdown('<div class=\"sub-header\">üìÑ Sources utilis√©es</div>', unsafe_allow_html=True)\n",
    "            source_docs = result[\"source_docs\"]\n",
    "            \n",
    "            if source_docs:\n",
    "                sources_data = []\n",
    "                for i, doc in enumerate(source_docs):\n",
    "                    source_name = os.path.basename(doc.metadata.get('source', 'Inconnu'))\n",
    "                    page_num = None\n",
    "                    import re\n",
    "                    if 'page' in doc.metadata:\n",
    "                        page_num = doc.metadata['page']\n",
    "                    elif 'header1' in doc.metadata and 'Page ' in doc.metadata['header1']:\n",
    "                        page_num = doc.metadata['header1'].replace('Page ', '')\n",
    "                    elif 'header1' in doc.metadata:\n",
    "                        match = re.search(r'Page (\\d+)', doc.metadata['header1'])\n",
    "                        if match:\n",
    "                            page_num = match.group(1)\n",
    "                    if page_num is None:\n",
    "                        match = re.search(r'# Page (\\d+)', doc.page_content)\n",
    "                        page_num = match.group(1) if match else 'N/A'\n",
    "                    \n",
    "                    context = doc.metadata.get('header1', '') + ' > ' + doc.metadata.get('header2', '')\n",
    "                    similarity = doc.metadata.get('score', 'N/A') if 'score' in doc.metadata else 'N/A'\n",
    "                    \n",
    "                    sources_data.append({\n",
    "                        \"N¬∞\": i+1,\n",
    "                        \"Document\": source_name,\n",
    "                        \"Page\": page_num,\n",
    "                        \"Contexte\": context,\n",
    "                        \"Pertinence\": similarity if isinstance(similarity, float) else 'N/A',\n",
    "                        \"Extrait\": doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content\n",
    "                    })\n",
    "                \n",
    "                st.markdown('<div class=\"dataframe-container\">', unsafe_allow_html=True)\n",
    "                st.dataframe(\n",
    "                    pd.DataFrame(sources_data),\n",
    "                    use_container_width=True,\n",
    "                    column_config={\n",
    "                        \"N¬∞\": st.column_config.NumberColumn(\"N¬∞\", width=\"small\"),\n",
    "                        \"Document\": st.column_config.TextColumn(\"Document\", width=\"medium\"),\n",
    "                        \"Page\": st.column_config.TextColumn(\"Page\", width=\"small\"),\n",
    "                        \"Contexte\": st.column_config.TextColumn(\"Contexte\", width=\"medium\"),\n",
    "                        \"Extrait\": st.column_config.TextColumn(\"Extrait\", width=\"large\"),\n",
    "                        \"Pertinence\": st.column_config.ProgressColumn(\n",
    "                            \"Pertinence\", \n",
    "                            min_value=0, \n",
    "                            max_value=1,\n",
    "                            format=\"%.2f\"\n",
    "                        ) if any(isinstance(x.get(\"Pertinence\"), float) for x in sources_data) else None\n",
    "                    }\n",
    "                )\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "                if show_visualization and len(source_docs) > 1:\n",
    "                    try:\n",
    "                        st.markdown('<div class=\"sub-header\">üìä Visualisation des chunks</div>', unsafe_allow_html=True)\n",
    "                        viz_data = pd.DataFrame(sources_data)\n",
    "                        st.subheader(\"Distribution des chunks par document\")\n",
    "                        doc_counts = viz_data[\"Document\"].value_counts()\n",
    "                        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "                        doc_counts.plot(kind='pie', autopct='%1.1f%%', ax=ax)\n",
    "                        plt.ylabel('')\n",
    "                        st.pyplot(fig)\n",
    "                        \n",
    "                        pertinence_cols = [col for col in viz_data.columns if 'Pertinence' in col]\n",
    "                        if pertinence_cols and viz_data[pertinence_cols[0]].apply(lambda x: isinstance(x, (int, float))).any():\n",
    "                            st.subheader(\"Pertinence des chunks r√©cup√©r√©s\")\n",
    "                            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                            sns.barplot(x=\"N¬∞\", y=pertinence_cols[0], data=viz_data, palette=\"viridis\", ax=ax)\n",
    "                            ax.set_title(\"Score de similarit√© par chunk\")\n",
    "                            ax.set_ylabel(\"Score de similarit√©\")\n",
    "                            ax.set_xlabel(\"Num√©ro du chunk\")\n",
    "                            plt.tight_layout()\n",
    "                            st.pyplot(fig)\n",
    "                    except Exception as e:\n",
    "                        st.info(f\"Impossible de g√©n√©rer la visualisation. Erreur: {str(e)}\")\n",
    "            else:\n",
    "                st.info(\"Aucune source pertinente trouv√©e. Essayez d'ajuster le seuil de similarit√© ou les param√®tres de filtrage.\")\n",
    "            \n",
    "            st.markdown(\"### √âvaluation de la r√©ponse\")\n",
    "            feedback = st.radio(\n",
    "                \"Cette r√©ponse √©tait-elle utile?\",\n",
    "                [\"Tr√®s utile\", \"Partiellement utile\", \"Pas utile\"]\n",
    "            )\n",
    "            feedback_text = st.text_area(\"Commentaires suppl√©mentaires (facultatif):\", height=100, key=\"feedback\")\n",
    "            if st.button(\"Envoyer l'√©valuation\"):\n",
    "                st.success(\"Merci pour votre feedback! Il nous aidera √† am√©liorer le syst√®me.\")\n",
    "    else:\n",
    "        st.error(\"Impossible de charger l'index FAISS. Veuillez v√©rifier que l'index existe et est accessible.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 21:19:17.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.159 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.160 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.160 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.162 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:19:17.176 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Onglet 2: Gestion des documents\n",
    "with tab2:\n",
    "    st.markdown('<div class=\"sub-header\">üì§ Ajouter de nouveaux documents</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Section am√©lior√©e pour l'upload de fichiers\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"info-box\">\n",
    "    Cette section vous permet d'ajouter de nouveaux documents PDF √† l'index. Les fichiers seront automatiquement trait√©s,\n",
    "    d√©coup√©s en chunks et index√©s pour √™tre disponibles dans vos recherches.\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Zone d'upload bien visible\n",
    "    uploaded_files = st.file_uploader(\n",
    "        \"T√©l√©chargez vos fichiers PDF\",\n",
    "        type=['pdf'],\n",
    "        accept_multiple_files=True,\n",
    "        help=\"Vous pouvez t√©l√©charger plusieurs fichiers PDF simultan√©ment\"\n",
    "    )\n",
    "    \n",
    "    # Param√®tres de traitement des PDF\n",
    "    with st.expander(\"Param√®tres avanc√©s de traitement\"):\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            chunk_size = st.slider(\"Taille des chunks\", 200, 1000, 350, 50,\n",
    "                                help=\"Plus petite taille = plus de pr√©cision, plus grande taille = plus de contexte\")\n",
    "        with col2:\n",
    "            chunk_overlap = st.slider(\"Chevauchement\", 0, 200, 50, 10,\n",
    "                                    help=\"Contr√¥le le chevauchement entre les chunks pour pr√©server le contexte\")\n",
    "        \n",
    "        embedding_model = st.selectbox(\n",
    "            \"Mod√®le d'embedding\",\n",
    "            [\"text-embedding-3-small\", \"text-embedding-3-large\"],\n",
    "            index=0,\n",
    "            help=\"Mod√®le utilis√© pour cr√©er les embeddings vectoriels\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Fonction pour traiter les nouveaux fichiers\n",
    "    def process_uploaded_files(uploaded_files, vector_store):\n",
    "        if not uploaded_files:\n",
    "            return vector_store, 0\n",
    "        \n",
    "        # Cr√©er un dossier temporaire pour les fichiers\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        # Enregistrer les fichiers t√©l√©charg√©s\n",
    "        pdf_paths = []\n",
    "        for uploaded_file in uploaded_files:\n",
    "            file_path = os.path.join(temp_dir, uploaded_file.name)\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(uploaded_file.getbuffer())\n",
    "            pdf_paths.append(file_path)\n",
    "        \n",
    "        # Initialiser le text splitter pour un chunking plus fin\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "        # Traiter chaque fichier\n",
    "        new_chunks = []\n",
    "        for pdf_path in pdf_paths:\n",
    "            try:\n",
    "                # Utiliser PyMuPDF pour extraire texte et tableaux\n",
    "                doc = fitz.open(pdf_path)\n",
    "                pdf_text = \"\"\n",
    "                \n",
    "                doc_metadata = {\n",
    "                    \"source\": pdf_path,\n",
    "                    \"title\": os.path.basename(pdf_path),\n",
    "                    \"total_pages\": len(doc)\n",
    "                }\n",
    "                \n",
    "                for page_num, page in enumerate(doc):\n",
    "                    # Extraire le texte\n",
    "                    text = page.get_text(\"text\")\n",
    "                    \n",
    "                    # Extraire les tableaux en format texte structur√©\n",
    "                    tables = page.get_text(\"blocks\")\n",
    "                    table_text = \"\"\n",
    "                    for block in tables:\n",
    "                        if len(block) > 6 and block[6] == 1:  # Type 1 = table\n",
    "                            table_text += f\"\\nTableau: {block[4]}\\n\"\n",
    "                    \n",
    "                    # Extraire et d√©crire les images\n",
    "                    image_info = \"\"\n",
    "                    for img in page.get_images(full=True):\n",
    "                        image_info += f\"\\n[Image: {img[0]}]\\n\"\n",
    "                    \n",
    "                    # Combiner avec des marqueurs de structure\n",
    "                    page_content = f\"# Page {page_num+1}\\n{text}\\n{table_text}\\n{image_info}\"\n",
    "                    pdf_text += page_content\n",
    "                \n",
    "                # D√©couper avec pr√©servation de la structure\n",
    "                try:\n",
    "                    header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[\n",
    "                        (\"#\", \"header1\"),\n",
    "                        (\"##\", \"header2\"),\n",
    "                    ])\n",
    "                    md_header_splits = header_splitter.split_text(pdf_text)\n",
    "                    \n",
    "                    # D√©couper en chunks tout en pr√©servant les m√©tadonn√©es hi√©rarchiques\n",
    "                    chunks = []\n",
    "                    for split in md_header_splits:\n",
    "                        # Pr√©server le contexte hi√©rarchique dans les m√©tadonn√©es\n",
    "                        split_metadata = {**doc_metadata, **split.metadata}\n",
    "                        # D√©couper davantage si n√©cessaire\n",
    "                        smaller_chunks = text_splitter.split_text(split.page_content)\n",
    "                        # Cr√©er des Documents avec contexte pr√©serv√©\n",
    "                        for chunk in smaller_chunks:\n",
    "                            chunks.append(Document(page_content=chunk, metadata=split_metadata))\n",
    "                except Exception as e:\n",
    "                    # Fallback si le d√©coupage hi√©rarchique √©choue\n",
    "                    chunks = []\n",
    "                    pages = [Document(page_content=page.get_text(\"text\"), \n",
    "                                     metadata={\"source\": pdf_path, \"page\": i+1}) \n",
    "                            for i, page in enumerate(doc)]\n",
    "                    chunks = text_splitter.split_documents(pages)\n",
    "                \n",
    "                new_chunks.extend(chunks)\n",
    "            except Exception as e:\n",
    "                st.error(f\"Erreur avec {os.path.basename(pdf_path)}: {str(e)}\")\n",
    "        \n",
    "        # Cr√©er les embeddings et ajouter √† l'index\n",
    "        if new_chunks:\n",
    "            try:\n",
    "                # S'assurer que l'instance d'embeddings est disponible\n",
    "                embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "                \n",
    "                # Ajouter directement les documents √† FAISS\n",
    "                vector_store.add_documents(new_chunks)\n",
    "                \n",
    "                # Sauvegarde de l'index FAISS mis √† jour\n",
    "                vector_store.save_local(index_folder)\n",
    "                \n",
    "                # Nettoyer les fichiers temporaires\n",
    "                shutil.rmtree(temp_dir)\n",
    "                \n",
    "                return vector_store, len(new_chunks)\n",
    "            except Exception as e:\n",
    "                st.error(f\"Erreur lors de la mise √† jour de l'index: {str(e)}\")\n",
    "        \n",
    "        # Nettoyer les fichiers temporaires\n",
    "        shutil.rmtree(temp_dir)\n",
    "        \n",
    "        return vector_store, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 21:21:37.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.051 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:37.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # Bouton pour d√©clencher le traitement avec barre de progression\n",
    "    if uploaded_files:\n",
    "        if st.button(\"üì• Traiter et indexer les fichiers\", type=\"primary\", use_container_width=True):\n",
    "            with st.spinner(\"Traitement des fichiers en cours...\"):\n",
    "                progress_bar = st.progress(0)\n",
    "                total_files = len(uploaded_files)\n",
    "                \n",
    "                for i, _ in enumerate(uploaded_files):\n",
    "                    progress_bar.progress((i + 1) / total_files)\n",
    "                \n",
    "                vector_store, num_added = process_uploaded_files(uploaded_files, vector_store)\n",
    "                \n",
    "                if num_added > 0:\n",
    "                    st.success(f\"‚úÖ {num_added} nouveaux chunks ont √©t√© ajout√©s √† l'index √† partir de {len(uploaded_files)} fichiers!\")\n",
    "                    # Rafra√Æchir les donn√©es\n",
    "                    st.cache_data.clear()\n",
    "                    st.experimental_rerun()\n",
    "                else:\n",
    "                    st.error(\"‚ùå Aucun chunk n'a pu √™tre ajout√©. V√©rifiez les fichiers et r√©essayez.\")\n",
    "    \n",
    "    # Afficher les statistiques sur l'index actuel\n",
    "    st.markdown('<div class=\"sub-header\">üìä Statistiques de l\\'index</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    if success:\n",
    "        try:\n",
    "            # R√©cup√©rer les statistiques\n",
    "            all_docs = vector_store.docstore._dict.values()\n",
    "            total_chunks = len(vector_store.index_to_docstore_id)\n",
    "            \n",
    "            # Analyser les documents\n",
    "            sources_dict = {}\n",
    "            pages_dict = {}\n",
    "            \n",
    "            for doc in all_docs:\n",
    "                source = os.path.basename(doc.metadata.get('source', 'Inconnu'))\n",
    "                if source in sources_dict:\n",
    "                    sources_dict[source] += 1\n",
    "                else:\n",
    "                    sources_dict[source] = 1\n",
    "                \n",
    "                page = doc.metadata.get('page', 'N/A')\n",
    "                if source in pages_dict:\n",
    "                    if page not in pages_dict[source]:\n",
    "                        pages_dict[source].append(page)\n",
    "                else:\n",
    "                    pages_dict[source] = [page]\n",
    "            \n",
    "            # Afficher les statistiques g√©n√©rales\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{total_chunks}</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Chunks totaux</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "            with col2:\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{len(sources_dict)}</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Documents</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "            with col3:\n",
    "                total_pages = sum(len(pages) for pages in pages_dict.values())\n",
    "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
    "                st.markdown(f'<div class=\"metric-value\">{total_pages}</div>', unsafe_allow_html=True)\n",
    "                st.markdown('<div class=\"metric-label\">Pages</div>', unsafe_allow_html=True)\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "            \n",
    "            # Visualiser la r√©partition des chunks\n",
    "            if sources_dict:\n",
    "                st.subheader(\"R√©partition des chunks par document\")\n",
    "                \n",
    "                # Cr√©er un dataframe pour la visualisation\n",
    "                df_sources = pd.DataFrame({\n",
    "                    'Document': list(sources_dict.keys()),\n",
    "                    'Nombre de chunks': list(sources_dict.values())\n",
    "                })\n",
    "                \n",
    "                # Trier par nombre de chunks\n",
    "                df_sources = df_sources.sort_values('Nombre de chunks', ascending=False)\n",
    "                \n",
    "                # Cr√©er le graphique\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.barplot(x='Document', y='Nombre de chunks', data=df_sources, palette='viridis', ax=ax)\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                st.pyplot(fig)\n",
    "                \n",
    "                # Afficher le tableau d√©taill√©\n",
    "                st.subheader(\"D√©tails des documents index√©s\")\n",
    "                \n",
    "                # Pr√©parer les donn√©es pour le tableau\n",
    "                table_data = []\n",
    "                for source, chunks in sources_dict.items():\n",
    "                    pages = len(pages_dict.get(source, []))\n",
    "                    table_data.append({\n",
    "                        \"Document\": source,\n",
    "                        \"Nombre de chunks\": chunks,\n",
    "                        \"Nombre de pages\": pages,\n",
    "                        \"Chunks/page\": round(chunks / max(1, pages), 2)\n",
    "                    })\n",
    "                \n",
    "                # Afficher le tableau\n",
    "                st.markdown('<div class=\"dataframe-container\">', unsafe_allow_html=True)\n",
    "                st.dataframe(\n",
    "                    pd.DataFrame(table_data),\n",
    "                    use_container_width=True,\n",
    "                    hide_index=True\n",
    "                )\n",
    "                st.markdown('</div>', unsafe_allow_html=True)\n",
    "                \n",
    "        except Exception as e:\n",
    "            st.error(f\"Erreur lors de la r√©cup√©ration des statistiques: {str(e)}\")\n",
    "    else:\n",
    "        st.error(\"Index FAISS non charg√©. Impossible d'afficher les statistiques.\")\n",
    "    \n",
    "    # Option pour r√©initialiser l'index\n",
    "    with st.expander(\"‚ö†Ô∏è R√©initialiser l'index\"):\n",
    "        st.warning(\"Attention: Cette op√©ration supprimera d√©finitivement l'index FAISS actuel et toutes les donn√©es qu'il contient.\")\n",
    "        if st.button(\"üóëÔ∏è R√©initialiser l'index\", use_container_width=True):\n",
    "            confirm = st.text_input(\"Tapez 'CONFIRMER' pour r√©initialiser l'index\", key=\"confirm_reset\")\n",
    "            if confirm == \"CONFIRMER\":\n",
    "                try:\n",
    "                    # Supprimer l'index\n",
    "                    if os.path.exists(os.path.join(index_folder, \"index.faiss\")):\n",
    "                        os.remove(os.path.join(index_folder, \"index.faiss\"))\n",
    "                    if os.path.exists(os.path.join(index_folder, \"index.pkl\")):\n",
    "                        os.remove(os.path.join(index_folder, \"index.pkl\"))\n",
    "                    \n",
    "                    st.success(\"‚úÖ Index r√©initialis√© avec succ√®s! L'application va red√©marrer.\")\n",
    "                    st.cache_data.clear()\n",
    "                    st.cache_resource.clear()\n",
    "                    st.experimental_rerun()\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Erreur lors de la r√©initialisation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 21:21:41.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.525 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 21:21:41.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Pied de page\n",
    "st.markdown(\"---\")\n",
    "col1, col2 = st.columns([3, 1])\n",
    "with col1:\n",
    "    st.markdown(\"D√©velopp√© avec RAG avanc√© et Streamlit\")\n",
    "with col2:\n",
    "    st.markdown(\"Version: 3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
